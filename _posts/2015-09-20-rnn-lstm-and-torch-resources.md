---
layout: post
title:  "Resoruces for learning about RNNs, LSTMs, and Torch"
---

Here's a very partial list of resources that might come in handy.

#### Torch and Lua

0. The [Lua manual](http://www.lua.org/manual/5.3/contents.html#contents).
0. [Documentation for Torch](https://github.com/torch/torch7/tree/master/doc).
0. [Paper introducing Torch](http://cs.nyu.edu/~koray/files/2011_torch7_nipsw.pdf).
0. [Documentation for nn](https://github.com/torch/nn/blob/master/doc/overview.md).
0. [nngraph library](https://github.com/torch/nngraph).
0. [Penlight](http://stevedonovan.github.io/Penlight/api/manual/01-introduction.md.html), a python-inspired library for Lua.
0. [cutorch](https://github.com/torch/cutorch) documentation for using GPUs with Torch.

#### Recurrent neural nets, including LSTMs

0. Wojciech Zaremba's [LSTM implementation](https://github.com/wojzaremba/lstm), on which I based my own.
0. Andrej Karpathy's blog post,
[The unreasonable effectiveness of recurrent nerual networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
0. Yoshua Bengio's [Practical recommendations for gradient-based training of deep architectures](http://arxiv.org/pdf/1206.5533v2.pdf).
0. A deep learning with Torch [slidedeck](http://learning.cs.toronto.edu/wp-content/uploads/2015/02/torch_tutorial.pdf) by Jimmy Ba at the University of Toronto.
0. Alex Graves [formulation of LSTMs](http://arxiv.org/pdf/1308.0850v5.pdf), which I follow.
